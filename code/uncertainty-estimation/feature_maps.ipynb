{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "import json\n",
    "%matplotlib inline\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(r'Z:\\grodriguez\\CardiacOCT\\model_trial_8.pt')\n",
    "for i in range(len(model)):\n",
    "  model[i] = model[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModuleList(\n",
       "   (0-2): 3 x Sequential(\n",
       "     (0): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (3): Sequential(\n",
       "     (0): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (4): Sequential(\n",
       "     (0): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (5): Sequential(\n",
       "     (0): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (6): Sequential(\n",
       "     (0): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " ModuleList(\n",
       "   (0): StackedConvLayers(\n",
       "     (blocks): Sequential(\n",
       "       (0): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "       (1): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): StackedConvLayers(\n",
       "     (blocks): Sequential(\n",
       "       (0): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "       (1): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): StackedConvLayers(\n",
       "     (blocks): Sequential(\n",
       "       (0): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "       (1): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (3): StackedConvLayers(\n",
       "     (blocks): Sequential(\n",
       "       (0): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "       (1): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (4): StackedConvLayers(\n",
       "     (blocks): Sequential(\n",
       "       (0): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "       (1): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (5-6): 2 x StackedConvLayers(\n",
       "     (blocks): Sequential(\n",
       "       (0): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "       (1): ConvDropoutNormNonlin(\n",
       "         (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "         (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (7): Sequential(\n",
       "     (0): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): StackedConvLayers(\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvDropoutNormNonlin(\n",
       "           (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "           (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " ModuleList(),\n",
       " ModuleList(\n",
       "   (0-2): 3 x ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "   (3): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "   (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "   (5): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "   (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       " ),\n",
       " ModuleList(\n",
       "   (0-2): 3 x Conv2d(480, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (3): Conv2d(256, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (4): Conv2d(128, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (5): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (6): Conv2d(32, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       " )]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torch.load(r'Z:\\grodriguez\\CardiacOCT\\data-2d\\results\\nnUNet\\2d\\Task508_CardiacOCT\\nnUNetTrainer_V2_Loss_CEandDice_Weighted__nnUNetPlansv2.1\\fold_0\\model_final_checkpoint.model')\n",
    "state_dict = model_weights['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'batch_size': 4,\n",
       "  'num_pool_per_axis': [7, 7],\n",
       "  'patch_size': array([768, 768], dtype=int64),\n",
       "  'median_patient_size_in_voxels': array([  1, 691, 691], dtype=int64),\n",
       "  'current_spacing': array([999.,   1.,   1.]),\n",
       "  'original_spacing': array([999.,   1.,   1.]),\n",
       "  'pool_op_kernel_sizes': [[2, 2],\n",
       "   [2, 2],\n",
       "   [2, 2],\n",
       "   [2, 2],\n",
       "   [2, 2],\n",
       "   [2, 2],\n",
       "   [2, 2]],\n",
       "  'conv_kernel_sizes': [[3, 3],\n",
       "   [3, 3],\n",
       "   [3, 3],\n",
       "   [3, 3],\n",
       "   [3, 3],\n",
       "   [3, 3],\n",
       "   [3, 3],\n",
       "   [3, 3]],\n",
       "  'do_dummy_2D_data_aug': False}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = np.load(r'Z:\\grodriguez\\CardiacOCT\\data-2d\\results\\nnUNet\\2d\\Task508_CardiacOCT\\nnUNetTrainer_V2_Loss_CEandDice_Weighted__nnUNetPlansv2.1\\fold_0\\model_final_checkpoint.model.pkl', allow_pickle=True)\n",
    "model_params['plans']['plans_per_stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(691, 691, 22)\n",
      "torch.Size([1, 22, 691, 691])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image_sample = np.load(r'Z:\\grodriguez\\CardiacOCT\\data-2d\\nnUNet_preprocessed\\Task508_CardiacOCT\\nnUNetData_plans_v2.1_2D_stage0\\ESTNEMC0027_1_frame27_001.npz', allow_pickle=True)['data'][:,0,:,:].T\n",
    "print(image_sample.shape)\n",
    "image_sample=transform(image_sample)\n",
    "image_sample=image_sample.unsqueeze(0)\n",
    "image_sample = image_sample.to(device)\n",
    "print(image_sample.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_list = []\n",
    "\n",
    "for i in range(len(model)):\n",
    "\n",
    "  for module in model[i].modules():\n",
    "\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "      conv2d_list.append(module)\n",
    "\n",
    "conv2d_list = conv2d_list[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del conv2d_list[2:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_list = []\n",
    "\n",
    "for key, value in state_dict.items():\n",
    "\n",
    "  if 'conv.weight' in key.lower():\n",
    "\n",
    "    weights_list.append(value.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([480, 960, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([480, 960, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([480, 960, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([256, 512, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([128, 256, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([64, 128, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([32, 64, 3, 3])\n",
      "torch.Size([32, 32, 3, 3])\n",
      "torch.Size([32, 21, 3, 3])\n",
      "torch.Size([32, 32, 3, 3])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([480, 256, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n",
      "torch.Size([480, 480, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for i in weights_list:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [480, 960, 3, 3], expected input[1, 22, 691, 691] to have 960 channels, but got 22 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17232\\4129017325.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconv2d_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimage_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2d_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\NO_BACKUP\\anaconda3\\envs\\ai_master\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\NO_BACKUP\\anaconda3\\envs\\ai_master\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\NO_BACKUP\\anaconda3\\envs\\ai_master\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 459\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [480, 960, 3, 3], expected input[1, 22, 691, 691] to have 960 channels, but got 22 channels instead"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "names = []\n",
    "for layer in conv2d_list:\n",
    "    image_sample = layer(image_sample)\n",
    "    outputs.append(image_sample)\n",
    "    names.append(str(conv2d_list[layer]))\n",
    "    print('a')\n",
    "\n",
    "#print feature_maps\n",
    "for feature_map in outputs:\n",
    "    print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "for feature_map in outputs:\n",
    "    feature_map = feature_map.squeeze(0)\n",
    "    gray_scale = torch.sum(feature_map,2)\n",
    "    gray_scale = gray_scale / feature_map.shape[0]\n",
    "    processed.append(gray_scale.data.cpu().numpy())\n",
    "for fm in processed:\n",
    "    print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(30, 50))\n",
    "for i in range(len(processed)):\n",
    "    a = fig.add_subplot(5, 6, i+1)\n",
    "    imgplot = plt.imshow(processed[i].astype(np.uint8))\n",
    "    a.axis(\"off\")\n",
    "    a.set_title(names[i].split('(')[0], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
